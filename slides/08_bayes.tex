\documentclass[lualatex,handout]{beamer}
\setbeamertemplate{footline}[frame number]
\usepackage{luatexja}
\usepackage{amsmath,amssymb}

\usepackage{thm-restate}

%\usetheme{Berlin}
\usecolortheme{rose}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

%\usepackage[haranoaji]{luatexja-preset}
\usepackage[deluxe,ipaex]{luatexja-preset}
\renewcommand{\kanjifamilydefault}{\gtdefault}
%\setmainjfont{HaranoAjiGothic-Regular}

\usepackage{unicode-math}
%\setmathfont{Fira Math}
\setmathfont{STIX Two Math}
\setmathfont{STIX Two Math}[range=bfup/{Latin,latin,num,Greek,greek}]
\setmathfont{STIX Two Math}[range=bfit/{Latin,latin}]
\setmathfont{STIX Two Math}[range={"0000-"FFFF}]
\setmathrm{STIX Two Math}[StylisticSet=8]

%\usefonttheme{professionalfonts}

\usepackage{luacolor}

\newcommand{\mycolor}[2]{%
  \begingroup
  \colorlet{currentcolor}{.}%
  \color{#1}#2%
  \color{currentcolor}%
  \endgroup
}
\newcommand{\emm}[1]{\mycolor{red}{#1}}
\newcommand{\expt}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\var}[1]{\mathbb{V}\left[#1\right]}
\newcommand{\cov}[1]{\mathsf{Cov}\left[#1\right]}
\newcommand{\vc}[1]{\mathsf{Var}\left[#1\right]}

\DeclareMathOperator*{\argmax}{arg\,max}


\usepackage{xspace}
%\usepackage{bm}
%\newcommand\bm[1]{{\mathbf{#1}}}
\newcommand\defiff{\stackrel{\text{def}}{\iff}}
\newcommand\dx{{\,\mathrm{d}x}}
\newcommand\KL[2]{D\left(#1\,\|\,#2\right)}
\newcommand\dtv{d_{\mathrm{TV}}}

\theoremstyle{definition}

\title{確率・統計基礎: ベイズ推定}
\author{森 立平}
\date{}



\begin{document}
\begin{frame}[plain]
\maketitle
\end{frame}


\if0
\begin{frame}{統計的の問題}
データから知りたい情報を推定したい。

%現実の問題では確率分布が未知であることがほとんど

%\vspace{2em}
%確率分布や統計量を推定するのが統計の主な問題

%\vspace{2em}
%一番単純な設定では確率分布は$p$か$q$のどちらかを当てる設定。
\end{frame}
\fi

\begin{frame}{用語}
\begin{itemize}
\setlength{\itemsep}{2em}
\item $x\in A$: データ、知っているもの(今日は離散と仮定するが、本質的な仮定ではない)
%\item $\theta$: パラメータ、母数
\item $s\in B$: パラメータ、推定したいもの(今日は離散の場合を考える。連続のときは$\theta$という記号を使うことが多い)
\item $\Pr(S = s)$: 事前確率
\item $\Pr(X = x \mid S = s)$: 尤度
\item $\Pr(S = s \mid X = x)$: 事後確率
\end{itemize}
\end{frame}

\begin{frame}{最大事後確率推定}
\small
%識別したい分布の数が二つではなく、それ以上(有限個)の場合を考える。

\begin{block}{問題}
確率分布$\Pr(S = s,\, X = x)$が既知である。
与えられた$x\in A$から$s\in B$を推定したい。
推定関数$E\colon A\to B$の平均誤り確率は$\Pr(E(X)\ne S)$で定義される。
\end{block}

%$s$に対応する確率変数を$S$、$x$に対応する確率変数を$X$とおく。つまり
%\begin{align*}
%\Pr(S=s,\, X=x) &= \Pr(S = s) \Pr(X = x\mid S = s) = \lambda_s p_s(x).
%\end{align*}
\begin{align*}
\Pr(E(X) \ne S) &= 
1 - \Pr(S = E(X))\\
&=1 - \sum_{x \in A} \Pr(X = x)\Pr(S = E(X)\mid X = x)\\
&=1 - \sum_{x \in A} \Pr(X = x)\emm{\Pr(S = E(x)\mid X = x)}
%\sum_{s \in } \Pr(S = s)\Pr(E(X)\ne S\mid S = s)\\
%\sum_{x \in A} \Pr(X = x)\Pr(E(X)\ne S\mid X = x)\\
%&=\sum_{x \in A} \Pr(X = x)\Pr(E(x)\ne S\mid X = x)\\
%&=\sum_{x \in A} \Pr(X = x) \sum_{s\ne E(x)} \Pr(S=s\mid X = x)\\
%&=\sum_{x \in A} \Pr(X = x) (1- \Pr(S=E(x)\mid X = x))\\
%&=1- \sum_{x \in A} \Pr(X = x) \Pr(S=E(x)\mid X = x)\\
%\sum_{s \in S} \lambda_s \sum_{x \notin E^{-1}(s)} p_s(x)
\end{align*}
これを最小化したいので
$E(x)=\emm{\argmax_{s} \Pr(S=s\mid X=x)}$とするのが最適である。
これを\emm{最大事後確率推定}という。
\end{frame}

\begin{frame}{最尤推定}
\footnotesize
最大事後確率推定 (Maximum a posteriori probability estimation)
\begin{align*}
E_{\mathrm{MAP}}(x)\coloneq\emm{\argmax_{s} \Pr(S=s\mid X=x)}
\end{align*}
平均誤り確率を最小化する。事前分布を知らないと使えない。

\vspace{1.5em}
最尤推定 (Maximum likelihood estimation)
\begin{align*}
E_{\mathrm{ML}}(x)\coloneq\emm{\argmax_{s} \Pr(X=x\mid S=s)}
\end{align*}
平均誤り確率については何も言えない。事前分布を知らなくても使える。

\vspace{1.5em}
\emm{事前分布が一様分布}$P(S=s)=\frac1{|B|}$のとき、
\begin{align*}
\argmax_{s}\, \Pr(S=s\mid X=x)
&= \argmax_{s}\, \frac{\Pr(S=s,\, X=x)}{\Pr(X=x)}\\
&= \argmax_{s}\, \Pr(S=s,\, X=x)\\
&= \argmax_{s}\, \Pr(S=s)\Pr(X=x\mid S = s)\\
%&= \argmax_{s}\, \frac1{|B|}\Pr(X=x\mid S = s)\\
&\emm{=} \argmax_{s}\, \Pr(X=x\mid S = s)
\end{align*}
最大事後確率推定と最尤推定は等しい。
\end{frame}

\if0
\begin{frame}{例}

\end{frame}
\fi

\begin{frame}{二値の推定}
\footnotesize
$B = \{0,1\}$の状況を考える。以下のように$p_0(x),\,p_1(x)$を定義する。

\begin{align*}
p_0(x) &\coloneq \Pr(X=x\mid S=0)\\
p_1(x) &\coloneq \Pr(X=x\mid S=1)
\end{align*}

\vspace{.5em}
$\Pr(S=0)=\lambda$, $\Pr(S=1)=1-\lambda$とする。
最大事後確率推定では$\lambda p_0(x)$と$(1-\lambda)p_1(x)$を比較して、前者(もしくは後者)が大きい場合0(もしくは1)と推定する。
このとき
%平均誤り確率は
\begin{align*}
&\Pr(E_{\mathrm{MAP}}(X) = S) - \Pr(E_{\mathrm{MAP}}(X)\ne S)\\
&= \sum_s \Pr(S=s) \Pr(E_{\mathrm{MAP}}(X) = S\mid S = s)
- \sum_s \Pr(S=s) \Pr(E_{\mathrm{MAP}}(X) \ne S\mid S = s)\\
&=\sum_{x\in E_{\mathrm{MAP}}^{-1}(0)} \lambda p_0(x) + \sum_{x\in E_{\mathrm{MAP}}^{-1}(1)} (1-\lambda)p_1(x)\\
&\quad -\left(\sum_{x\in E_{\mathrm{MAP}}^{-1}(1)} \lambda p_0(x) + \sum_{x\in E_{\mathrm{MAP}}^{-1}(0)} (1-\lambda)p_1(x)\right)\\
&=\sum_{x\in E_{\mathrm{MAP}}^{-1}(0)} (\lambda p_0(x) - (1-\lambda)p_1(x))
-\left(\sum_{x\in E_{\mathrm{MAP}}^{-1}(1)} (\lambda p_0(x) - (1-\lambda)p_1(x))\right)\\
&=\emm{\sum_{x\in A} \left|\lambda p_0(x) - (1-\lambda)p_1(x)\right|}
\end{align*}
\end{frame}

%\begin{frame}{ベイズ}
%\end{frame}

\if0
\begin{frame}{ベイズ}
\begin{block}{問題}
確率$\lambda\in[0,1]$で確率分布$p_0\in\mathcal{P}$、確率$1-\lambda$で確率分布$p_1\in\mathcal{P}$
が選ばれ、その分布に従って$x\in A$が定まる。

\vspace{1em}
$x$を見て選ばれた分布が$p_0$か$p_1$か決定せよ。
\end{block}

\begin{example}
\begin{itemize}
\item $A=\{0,1\}^{100}$
\item $p_0$が成功確率$1/2$、試行回数$100$の二項分布
\item $p_1$が成功確率$1/3$、試行回数$100$の二項分布
\end{itemize}
\end{example}

\vspace{1em}
$p_0$と$p_1$を識別する関数$E\colon A\to\{0,1\}$とすると、その誤り確率は

\begin{align*}
%\min_{E\colon A\to \{0,1\}}
% \left(
\lambda \sum_{x\in E^{-1}(1)} p_0(x) + (1-\lambda) \sum_{x\in E^{-1}(0)}p_1(x)
% \right)
\end{align*}
\end{frame}

\begin{frame}{最小誤り確率}
\small
\begin{align*}
&\min_{E\colon A\to \{0,1\}}
 \left( \lambda \sum_{x\in E^{-1}(1)} p_0(x) + (1-\lambda) \sum_{x\in E^{-1}(0)}p_1(x) \right)\\
&=\min_{E\colon A\to \{0,1\}}
 \left( \lambda \sum_{x\in E^{-1}(1)} p_0(x) + (1-\lambda) \left(1-\sum_{x\in E^{-1}(1)}p_1(x) \right)\right)\\
&=\min_{E\colon A\to \{0,1\}}
 \left( (1-\lambda) + \sum_{x\in E^{-1}(1)} \left(\lambda p_0(x) - (1-\lambda) p_1(x) \right)\right)\\
&= (1-\lambda) + \min_{B\subseteq A} \left(\sum_{x\in B} \left(\lambda p_0(x) - (1-\lambda) p_1(x) \right)\right)\\
\end{align*}
ここで$\sum_{x\in B}$の部分は\emm{項が負のところだけ足す}ときに最小化されるので
\begin{align*}
&  (1-\lambda) + \frac{\left(\sum_{x\in A}\lambda p_0(x) - (1-\lambda) p_1(x) \right) - \sum_{x\in A}\left|\lambda p_0(x) - (1-\lambda) p_1(x) \right|}2\\
&=\frac{1-\emm{\sum_{x\in A}\left|\lambda p_0(x) - (1-\lambda) p_1(x) \right|}}2.
\end{align*}
\end{frame}
\fi

\begin{frame}{全変動距離}
最小誤り確率は
\begin{align*}
\frac{1-\emm{\sum_{x\in A}\left|\lambda p_0(x) - (1-\lambda) p_1(x) \right|}}2.
\end{align*}
特に$\lambda=1/2$のとき、
\begin{align*}
\frac{1-\emm{\frac12\sum_{x\in A}\left|p_0(x) - p_1(x) \right|}}2.
\end{align*}
\begin{definition}[全変動距離(Total variation distance)]
$p,\, q\in\mathcal{P}$についてその全変動距離$\dtv(p,\,q)$を以下で定義する。
\begin{align*}
\dtv(p,\, q) &\coloneq
\frac12\sum_{x\in A}\left|p(x) - q(x) \right|.
\end{align*}
\end{definition}
\end{frame}



\begin{frame}{平均誤り確率の漸近的挙動}
\small
二種類あるコインの片方を選んで独立に何回も投げる。
どちらのコインを選んだのか推定したい。
\begin{align*}
\Pr(\symbf{X}=\symbf{x},\, S= s) &= \Pr(S=s)\prod_{k=1}^N \Pr(X_k=x_k \mid S=s)
\end{align*}
誤り確率は
\begin{align*}
\sum_{\symbf{x}\in A^N}\left|\lambda\prod_k p_0(x_k) - (1-\lambda)\prod_kp_1(x_k) \right|.
\end{align*}
から定まるが、これを見ても$N\to\infty$の挙動はよく分からない。
$p(s)\coloneq \Pr(S=s)$,
$p(x\mid s) \coloneq \Pr(X=x\mid S=s),\, p(\symbf{x}\mid s)\coloneq \prod_k p(x_k\mid s)$とすると、
\begin{align*}
\Pr\left(E_{\mathrm{MAP}}(\symbf{X}) \ne S\right)
&= \Pr\left(p(S) p(\symbf{X}\mid S) \le p(\overline{S}) p(\symbf{X}\mid \overline{S})\right)\\
&= \Pr\left(\emm{\sum_k \log\frac{p(X_k\mid S)}{p(X_k\mid \overline{S})}} \le \log\frac{p(\overline{S})}{p(S)}\right).
\end{align*}
(不等号が等号の場合は$1/2$の確率でエラーになるが、簡単のためそれはエラーと数えることにする)。
\end{frame}

\begin{frame}{平均誤り確率の漸近的挙動}
\footnotesize
\begin{align*}
\Pr\left(\emm{\sum_k \log\frac{p(X_k\mid S)}{p(X_k\mid \overline{S})}} \le \log\frac{p(\overline{S})}{p(S)}\right)
&=
\lambda \Pr\left(\emm{\sum_k \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le \log\frac{1-\lambda}{\lambda}\mid S=0\right)\\
&+
(1-\lambda) \Pr\left(\emm{\sum_k \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \le \log\frac{\lambda}{1-\lambda}\mid S=1\right)
\end{align*}
この確率はクラメールの定理で漸近評価できる。

%\begin{align*}
%\Pr\left(\emm{\sum_k \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} < \log\frac{p(1)}{p(0)}\mid S=0\right)
%&= \Pr\left(\emm{\prod_k \sqrt{\frac{p(X_k\mid 1)}{p(X_k\mid 0)}}} > \sqrt{\frac{p(0)}{p(1)}}\mid S=0\right)\\
%\end{align*}

\end{frame}

\begin{frame}{課題}
\small
$A=\{0,1,2\},\,B=\{0, 1\}$とし、
\begin{align*}
\Pr(S = 0) &= 1/4&
\Pr(S = 1) &= 3/4\\
\Pr(X=0\mid S=0) &= 1/6&
\Pr(X=1\mid S=0) &= 2/6&
\Pr(X=2\mid S=0) &= 3/6\\
\Pr(X=0\mid S=1) &= 3/6&
\Pr(X=1\mid S=1) &= 1/6&
\Pr(X=2\mid S=1) &= 2/6\\
\end{align*}
とするとき、以下の問に答えよ。
\vspace{1em}
\begin{enumerate}
\setlength{\itemsep}{1em}
\item $X$から$S$を最大事後確率推定する関数$E_{\mathrm{MAP}}\colon A\to B$と最尤推定する関数$E_{\mathrm{ML}}\colon A\to B$をもとめよ。
%事後確率や尤度が等しい場合ものが複数ある場合は一様に選ぶことにせよ。
\item $X$から$S$を最大事後確率推定した場合の平均誤り確率をもとめよ。
\item $X$から$S$を最尤推定した場合の平均誤り確率をもとめよ。
\end{enumerate}
\end{frame}

\if0
\begin{frame}{おまけ 1/2}
\footnotesize
\begin{definition}[対称通信路]
$B=\{0,1\}$とする。
通信路$\Pr(X=s\mid S=s)$についてある置換$\sigma\colon A\to A$が存在して
$\sigma^2=\mathrm{id}$で
\begin{align*}
\Pr(X = x\mid S = 0) &= \Pr(X = \sigma(x)\mid S = 1)
\end{align*}
が成り立つとき$\Pr(X=x\mid S=s)$を\emm{対称通信路}という。
\end{definition}
$\lambda=1/2$と$\Pr(X=x\mid S=s)$が対称通信路であることを仮定すると、
\begin{align*}
&\lambda \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le \log\frac{1-\lambda}{\lambda}\mid S=0\right)\\
&\quad + (1-\lambda) \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \le \log\frac{\lambda}{1-\lambda}\mid S=1\right)\\
&=
\frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right)
+ \frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \le 0\mid S=1\right)\\
&=
\frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right)
+ \frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(\sigma(\sigma(X_k))\mid 0)}{p(\sigma(\sigma(X_k))\mid 1)}} \le 0\mid S=0\right)\\
&=
\Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right).
\end{align*}
\end{frame}

\begin{frame}{おまけ 2/2}
$Y=\log\frac{p(X\mid 1)}{p(X\mid 0)}$とすると、任意の$t\ge 0$について
\begin{align*}
\Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right)
&=\Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \ge 0\mid S=0\right)\\
&\le M_Y(t)^N.
\end{align*}
である。ここで
\begin{align*}
M_Y(t) &= \sum_{x\in A} p_0(x) \left(\frac{p_1(x)}{p_0(x)}\right)^t = \mathrm{e}^{-(1-t)D(p_1||p_0)}
\end{align*}
\begin{definition}[R\'enyi ダイバージェンス]
\begin{align*}
D_\alpha(q||p) &= \frac1{\alpha - 1} \log \sum_{x\in A} q^\alpha(x) p^{1-\alpha}(x)
\end{align*}
\end{definition}
\end{frame}
\fi

\end{document}
