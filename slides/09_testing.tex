\documentclass[lualatex,handout]{beamer}
\setbeamertemplate{footline}[frame number]
\usepackage{luatexja}
\usepackage{amsmath,amssymb}

\usepackage{thm-restate}

%\usetheme{Berlin}
\usecolortheme{rose}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

%\usepackage[haranoaji]{luatexja-preset}
\usepackage[deluxe,ipaex]{luatexja-preset}
\renewcommand{\kanjifamilydefault}{\gtdefault}
%\setmainjfont{HaranoAjiGothic-Regular}

\usepackage{unicode-math}
%\setmathfont{Fira Math}
\setmathfont{STIX Two Math}
\setmathfont{STIX Two Math}[range=bfup/{Latin,latin,num,Greek,greek}]
\setmathfont{STIX Two Math}[range=bfit/{Latin,latin}]
\setmathfont{STIX Two Math}[range={"0000-"FFFF}]
\setmathrm{STIX Two Math}[StylisticSet=8]

%\usefonttheme{professionalfonts}

\usepackage{luacolor}

\newcommand{\mycolor}[2]{%
  \begingroup
  \colorlet{currentcolor}{.}%
  \color{#1}#2%
  \color{currentcolor}%
  \endgroup
}
\newcommand{\emm}[1]{\mycolor{red}{#1}}
\newcommand{\expt}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\var}[1]{\mathbb{V}\left[#1\right]}
\newcommand{\cov}[1]{\mathsf{Cov}\left[#1\right]}
\newcommand{\vc}[1]{\mathsf{Var}\left[#1\right]}

\DeclareMathOperator*{\argmax}{arg\,max}


\usepackage{xspace}
%\usepackage{bm}
%\newcommand\bm[1]{{\mathbf{#1}}}
\newcommand\defiff{\stackrel{\text{def}}{\iff}}
\newcommand\dx{{\,\mathrm{d}x}}
\newcommand\KL[2]{D\left(#1\,\|\,#2\right)}
\newcommand\dtv{d_{\mathrm{TV}}}

\theoremstyle{definition}

\title{確率・統計基礎: 仮説検定}
\author{森 立平}
\date{}



\begin{document}
\begin{frame}[plain]
\maketitle
\end{frame}


\begin{frame}{仮説検定}
答が\emm{二値}の推定問題を考えたいが\emm{事前分布を適切に決める方法がない}。

\vspace{3em}
\begin{itemize}
\setlength{\itemsep}{2em}
\item 開発中の薬に効果があるかないか。
\item 患者が病気かどうか。
\item サイコロに偏りがあるかどうか。
\end{itemize}
\end{frame}

\begin{frame}{仮説検定}
\begin{itemize}
\setlength{\itemsep}{2em}
\item 対立仮説
\begin{itemize}
\setlength{\itemsep}{1em}
\item 開発中の薬に効果がある。
\item 患者が病気である。
\item サイコロに偏りがある。
\end{itemize}
\item 帰無仮説
\begin{itemize}
\setlength{\itemsep}{1em}
\item 開発中の薬に効果がない。
\item 患者が病気でない。
\item サイコロに偏りがない。
\end{itemize}
\end{itemize}

\vspace{2em}
帰無仮説を\emm{採択}or\emm{棄却}する。

対立仮説を採択or棄却するのではない。
\end{frame}

\begin{frame}{単純化した問題設定}
\footnotesize

以下では$s=0$が帰無仮説、$s=1$が対立仮説に対応しているとする。

検定関数$E\colon A\to\{0,1\}$は$E(x)=0$のとき帰無仮説を採択、$E(x)=1$のとき帰無仮説を棄却することを表す。
以下では\emm{確率的な検定関数}$E\colon A\to [0,1]$を考える。$E(x)\in[0,1]$は帰無仮説を\emm{棄却する確率}を表す。
(一般的には帰無仮説も対立仮説も分布の\emm{集合}となるが、ここではそれぞれ一つの分布であることに注意する)

\begin{block}{問題}
尤度関数$\Pr(X = x\mid S=s)$が既知である。
与えられた$x\in A$から$s\in \{0,1\}$を推定したい。
検定関数$E\colon A\to [0,1]$の
第一種誤り確率(有意水準)は$\alpha_E\coloneq\expt{E(X)\mid S= 0}$、
第二種誤り確率は$\beta_E\coloneq 1-\expt{E(X)\mid S= 1}$
で定義される。
\end{block}

\vspace{.5em}
第一種誤り確率を小さくしたければ$E(x) = 0$とすればよいし
第二種誤り確率を小さくしたければ$E(x) = 1$とすればよい。

\begin{definition}[最強力検定]
%検定関数$E\colon A\to \{0,1\}$が有意水準$\alpha\in[0,1]$の最強力検定であるとは以下を満たすことである。
%\begin{enumerate}
%\item $\alpha_E = \alpha$.
%\item $\beta_E = \min\{ \beta_{E'}\mid E', \alpha_{E'}\ge \alpha\}$.
%\end{enumerate}
検定関数$E\colon A\to \{0,1\}$が有意水準$\alpha\in[0,1]$の最強力検定$\defiff$$\alpha_E=\alpha$であり、
任意の$F\colon A\to\{0,1\}$について$\alpha_{F}\le \alpha$ならば$\beta_{F}\ge \beta_E$が成り立つ。
\end{definition}

\end{frame}

\begin{frame}{二種類の誤り確率}
\small
\centering
\begin{tikzpicture}
  \begin{scope}
    \clip (0,0) -- (5, 0) arc (0:90:5) -- cycle;
    \clip (5,5) -- (0, 5) arc (180:270:5) -- cycle;
    \fill[blue!30] (0,0) rectangle (5,5);
  \end{scope}

  
  \draw[thick, blue, domain=180:270, samples=100, very thick] plot ({5*cos(\x)+5}, {5*sin(\x)+5}) node[right] {};
  \draw[thick, blue, domain=0:90, samples=100, very thick] plot ({5*cos(\x)+0}, {5*sin(\x)+0}) node[right] {};

  \draw[->,very thick] node[below] {0} (-0,0) -- (5,0) node[below] {$1$} node[midway,below] {$\alpha$};
  \draw[->,very thick] (0,-0) -- (0,5) node[left] {$1$} node[midway,left] {$\beta$};
\end{tikzpicture}

\footnotesize
実現可能な$(\alpha,\beta)$の集合
%\begin{align*}
$\left\{(\alpha_E,\beta_E)\mid E\colon A\to[0,1]\right\}$
%\end{align*}
は凸集合である。

二つの検定関数$E_1$と$E_2$の確率混合$\lambda E_1(x) + (1-\lambda) E_2(x)$は
やはり検定関数で誤り確率も凸結合したものになる。

\vspace{1em}
$(\alpha, \beta)$が実現可能 $\iff$ $(1-\alpha, 1-\beta)$も実現可能

$1-E(x)$を考えればよい。
\end{frame}

\begin{frame}{尤度比検定}
事前分布が分かっている場合、
\begin{align*}
E_{\mathrm{MAP}}(x)&=
\begin{cases}
0&\text{if } \frac{\Pr(X = x\mid S = 0)}{\Pr(X = x\mid S = 1)} \ge \frac{\Pr(S = 1)}{\Pr(S = 0)}\\
1&\text{otherwise.}
\end{cases}
\end{align*}
が最適な検定関数となる。

\vspace{2em}
一般的に$\eta\ge 0,\,\kappa\in[0,1]$について
\begin{align*}
E(x)&=
\begin{cases}
\vspace{.5em}
0&\text{if } \frac{\Pr(X = x\mid S = 0)}{\Pr(X = x\mid S = 1)} > \eta\\\vspace{.5em}
1&\text{if } \frac{\Pr(X = x\mid S = 0)}{\Pr(X = x\mid S = 1)} < \eta\\
\kappa&\text{otherwise.}
\end{cases}
\end{align*}
という形の検定関数を用いた仮説検定を\emm{尤度比検定}という。
\end{frame}

\begin{frame}{ネイマン・ピアソンの補題}
\small
\begin{lemma}[ネイマン・ピアソンの補題]
%任意の$\alpha\in[0,1]$について、ある$\eta\in\mathbb{R}$が存在し、$E_\eta$は最強力検定である。
%任意の$\eta\in\mathbb{R}$について$E_\eta$は最強力検定である。
任意の尤度比検定は最強力検定である。
\end{lemma}
\begin{proof}
尤度比検定$E$における尤度比の閾値を$\eta\ge 0$とする。
\begin{align*}
p_0(x) &\coloneq \Pr(X = x\mid S = 0)&
p_1(x) &\coloneq \Pr(X = x\mid S = 1)
\end{align*}
とする。
%$L\coloneq\left\{x\in A\mid \frac{p_0(x)}{p_1(x)}\ge \eta\right\}$とおくと、
任意の$F\colon A\to[0,1]$について
\begin{align*}
&(F(x) - E(x)) (p_0(x) - \eta p_1(x))\ge 0\\
\iff&F(x)p_0(x) - E(x)p_0(x) - \eta F(x) p_1(x) + \eta E(x) p_1(x)\ge 0\\
\implies&\alpha_F - \alpha_E - \eta (1-\beta_F)  + \eta (1-\beta_E)\ge 0\\
\iff&(\alpha_F - \alpha_E) + \eta(\beta_F-\beta_E)\ge 0.
\end{align*}
よって$\alpha_F\ge\alpha_E$もしくは$\beta_F\ge\beta_E$である。
\end{proof}
\end{frame}

\begin{frame}{$N$回独立にサンプルする場合の尤度比検定}
\begin{align*}
\Pr(\symbf{X}=\symbf{x}\mid S = s) &= \prod_{k=1}^N \Pr(X_k=x_k\mid S = s)
\end{align*}
\begin{align*}
\log \frac{\Pr(\symbf{X}=\symbf{x}\mid S = 0)}{\Pr(\symbf{X}=\symbf{x}\mid S = 1)}
&=
\log \prod_{k=1}^N \frac{\Pr(X_k=x_k\mid S = 0)}{\Pr(X_k=x_k\mid S = 1)}\\
&=
\sum_{k=1}^N \log \frac{\Pr(X_k=x_k\mid S = 0)}{\Pr(X_k=x_k\mid S = 1)}\\
&=
N\sum_{x\in A} P_{\symbf{x}}(x) \log \frac{\Pr(X=x\mid S = 0)}{\Pr(X=x\mid S = 1)}\\
&=
N\sum_{x\in A} P_{\symbf{x}}(x) \log \frac{p_0(x)P_{\symbf{x}}(x)}{p_1(x)P_{\symbf{x}}(x)}\\
&=
N\left(\emm{\KL{P_{\symbf{x}}}{p_1} - \KL{P_{\symbf{x}}}{p_0}}\right)
\end{align*}
\end{frame}

\begin{frame}{漸近的な誤り確率 1/3}
\footnotesize
\begin{theorem}[シュタインの補題]
$\KL{p_0}{p_1}<\infty$とする。$\epsilon\in(0,1)$について
\begin{align*}
\beta_N^{\emm{\epsilon}} \coloneq \min_{\substack{E\colon A^N\to[0,1]\\ \alpha_E\le{\emm{\epsilon}}}} \beta_E
\end{align*}
とすると、任意の$\epsilon\in(0,1)$について
\begin{align*}
\lim_{N\to\infty}\frac1N \log\beta_N^{\emm{\epsilon}} &= -\KL{p_0}{p_1}.
\end{align*}
\end{theorem}
\begin{proof}[上界の証明]
%一般的以下が成り立つ。
$E$を尤度比検定関数で$\kappa=1$とする。
\begin{align*}
\alpha_E &= \Pr\left(\frac{p_0(\symbf{X})}{p_1(\symbf{X})} \le \eta\mid S = 0\right)\\
\beta_E &= \Pr\left(\frac{p_0(\symbf{X})}{p_1(\symbf{X})} > \eta\mid S = 1\right)
%\alpha_E &= \expt{E(\symbf{X})\mid S = 0}\\
%\beta_E &= 1-\expt{E(\symbf{X})\mid S = 1}
\end{align*}
%$E$は尤度比検定関数として一般性を失なわない。
%\begin{align*}
%\beta_E &= 1-\expt{E(\symbf{X})\mid S = 1}\\
%&= \sum_{q\in \mathcal{P}_N} \binom{N}{q_1N\, q_2N\,\dotsm q_mN} \left(\prod_{k=1}^m p_1(k)^{q_k N}\right) (1-E(q))\\
%&= \sum_{q\in \mathcal{P}_N} \binom{N}{q_1N\, q_2N\,\dotsm q_mN} \left(\prod_{k=1}^m p_0(k)^{q_k N}\right)\frac{\prod_{k=1}^m p_1(k)^{q_k N}}{\prod_{k=1}^m p_0(k)^{q_k N}} (1-E(q))
%\end{align*}
\end{proof}
\end{frame}

\begin{frame}{漸近的な誤り確率 2/3}
\small
\begin{align*}
\alpha_E &= \Pr\left(\frac1N\sum_{k=1}^N\log \frac{p_0(X_k)}{p_1(X_k)} \le \frac1N\log\eta\mid S = 0\right)\\
\beta_E &= \Pr\left(\frac1N\sum_{k=1}^N\log \frac{p_0(X_k)}{p_1(X_k)} > \frac1N\log\eta\mid S = 1\right)
\end{align*}
大数の弱法則やクラメールの定理により$\frac1N\sum_{k=1}^N\log \frac{p_0(X_k)}{p_1(X_k)}$は
\begin{align*}
\KL{p_0}{p_1} &= \sum_{x} p_0(x) \log\frac{p_0(x)}{p_1(x)}\qquad\text{if } S = 0\\
-\KL{p_1}{p_0} &= \sum_{x} p_1(x) \log\frac{p_0(x)}{p_1(x)}\qquad\text{if } S = 1
\end{align*}
に集中する。よって$E_N$において$\frac1N\log\eta = \KL{p_0}{p_1} - \delta$ とすると$\alpha_{E_N}\to 0$である。
\end{frame}

\begin{frame}{漸近的な誤り確率 3/3}
\small
\begin{align*}
\beta_{E_N} &= \Pr\left(\frac1N\sum_{k=1}^N\log \frac{p_0(X_k)}{p_1(X_k)} > \KL{p_0}{p_1}-\delta \mid S = 1\right)\\
% &= \Pr\left(\sum_{x\in A}P_{\symbf{x}}(x)\log \frac{p_0(x)}{p_1(x)} > \KL{p_0}{p_1}-\delta \mid S = 1\right)\\
% &= \Pr\left(\sum_{x\in A}P_{\symbf{x}}(x)\log \frac{p_0(x)P_{\symbf{x}}(x)}{p_1(x)P_{\symbf{x}}(x)} > \KL{p_0}{p_1}-\delta \mid S = 1\right)\\
&= \Pr\left(\KL{P_{\symbf{X}}}{p_1} - \KL{P_{\symbf{X}}}{p_0} > \KL{p_0}{p_1}-\delta \mid S = 1\right)\\
&\le \Pr\left(\KL{P_{\symbf{X}}}{p_1} > \KL{p_0}{p_1}-\delta \mid S = 1\right)
%&\le \mathrm{e}^{-(\KL{p_0}{p_1}-\delta)N}
\end{align*}
よってサノフの定理より
\begin{align*}
\limsup_{N\to\infty} \frac1N \log\beta_{E_N} &\le -\KL{p_0}{p_1}+\delta
\end{align*}
任意の$\delta>0$について成り立つので$\delta\to0$極限で
$\limsup_{N\to\infty} \frac1N \log\beta_{E_N} \le -\KL{p_0}{p_1}$.
\end{frame}

\if0
\begin{frame}{ベイズ推定の誤り指数}
\begin{align*}
\alpha_{E_{\mathrm{MAP}}} &= \Pr\left(\frac1N\sum_{k=1}^N\log \frac{p_0(X_k)}{p_1(X_k)} \le \frac1N\log\frac{\Pr(S=1)}{\Pr(S=0)}\mid S = 0\right)\\
&= \Pr\left(\KL{P_{\symbf{X}}}{p_1} - \KL{P_{\symbf{X}}}{p_0} \le \frac1N\log\frac{\Pr(S=1)}{\Pr(S=0)}\mid S = 0\right)\\
\beta_{E_{\mathrm{MAP}}} &= \Pr\left(\frac1N\sum_{k=1}^N\log \frac{p_0(X_k)}{p_1(X_k)} > \frac1N\log\frac{\Pr(S=1)}{\Pr(S=0)}\mid S = 1\right)\\
&= \Pr\left(\KL{P_{\symbf{X}}}{p_1} - \KL{P_{\symbf{X}}}{p_0} > \frac1N\log\frac{\Pr(S=1)}{\Pr(S=0)}\mid S = 1\right)
\end{align*}
\end{frame}
\fi

\begin{frame}{連続確率変数の場合}
\begin{itemize}
\setlength{\itemsep}{2em}
\item $x\in A$: データ、知っているもの、$A\subseteq \mathbb{R}$とか$A\subseteq\mathbb{R}^n$とか。
%\item $\emm{\theta \in \Theta}\colon$ パラメータ、母数、知りたいもの。
%$\Theta\subseteq\mathbb{R}$とか$\Theta\subseteq\mathbb{R}^n$とか。
%\item $s\in B$: パラメータ、推定したいもの(今日は離散の場合を考える。連続のときは$\theta$という記号を使うことが多い)
\item $s\in B$: パラメータ、知りたいもの、$B$は有限集合とする
\item $\Pr(S=s)$: 事前分布
\item $p(x \mid s)$: 尤度(条件付き確率密度関数)
\item $p(s \mid x)\coloneq p(x\mid s)\Pr(S=s) / p(x)$: 事後確率
\end{itemize}
\begin{align*}
\Pr(X\in B,\, S=s) &= \int_B  p(x\mid s)\Pr(S=s)\mathrm{d}x\\
p(x) &= \sum_{s\in B} p(x\mid s)\Pr(S=s)
\end{align*}
\end{frame}

\begin{frame}{連続確率変数の場合のMAP,ML推定}
最大事後確率推定 (Maximum a posteriori probability estimation)
\begin{align*}
E_{\mathrm{MAP}}(x)\coloneq\emm{\argmax_{s\in B} p(s\mid x)}
\end{align*}
\emm{平均誤り確率を最小化する}。事前分布を知らないと使えない。

\vspace{1.5em}
最尤推定 (Maximum likelihood estimation)
\begin{align*}
E_{\mathrm{ML}}(x)\coloneq\emm{\argmax_{s\in B} p(x\mid s)}
\end{align*}
平均誤り確率については何も言えない。事前分布を知らなくても使える。

\vspace{1.5em}
事前分布が一様分布のとき、最尤推定と最大事後確率推定は等しい。
\end{frame}

\begin{frame}{連続確率変数の場合の尤度比検定}
事前分布が分かっている場合、
\begin{align*}
E_{\mathrm{MAP}}(x)&=
\begin{cases}
0&\text{if } \frac{p(x\mid \theta_0)}{p(x\mid \theta_1)} \ge \frac{\Pr(S = \theta_1)}{\Pr(S = \theta_0)}\\
1&\text{otherwise.}
\end{cases}
\end{align*}
が最適な検定関数となる。

\vspace{1em}
一般的に$\eta\ge 0,\,\kappa\in[0,1]$について
\begin{align*}
E(x)&=
\begin{cases}
\vspace{.5em}
0&\text{if } \frac{p(x\mid \theta_0)}{p(x\mid \theta_1)} > \eta\\\vspace{.5em}
1&\text{if } \frac{p(x\mid \theta_0)}{p(x\mid \theta_1)} < \eta\\
\kappa&\text{otherwise.}
\end{cases}
\end{align*}
という形の検定関数を用いた仮説検定を\emm{尤度比検定}という。

\vspace{2em}
ネイマン・ピアソンの補題も成り立つ。
\end{frame}

\begin{frame}{分散が同じで既知な正規分布の尤度比検定}
\begin{align*}
p(x\mid \theta_0) &= \frac1{\sqrt{2\pi\sigma^2}} \mathrm{e}^{-\frac{(x-\theta_0)^2}{2\sigma^2}}\\
p(x\mid \theta_1) &= \frac1{\sqrt{2\pi\sigma^2}} \mathrm{e}^{-\frac{(x-\theta_1)^2}{2\sigma^2}}
\end{align*}
のとき、
\begin{align*}
\frac{p(x\mid \theta_0)}{p(x\mid \theta_1)} &= \mathrm{e}^{\frac{2(\theta_0-\theta_1)x+\theta_1^2-\theta_0^2}{2\sigma^2}}
\end{align*}
\begin{align*}
\log\frac{p(\symbf{x}\mid \theta_0)}{p(\symbf{x}\mid \theta_1)} &= N\frac{\theta_1^2-\theta_0^2}{2\sigma^2} + \frac{\theta_0-\theta_1}{\sigma^2}\emm{\sum_{k=1}^N x_k}
\end{align*}
なので$\sum_k x_k$の大きさを見て検定することになる。
\end{frame}

\begin{frame}{課題}
\small
$A=\{0,\,1\},\, B=\left\{p_0=\frac12,\,p_1=\frac13\right\}$とし、$k\in\{0,\,1\}$について
\begin{align*}
\Pr(X = 0 \mid S = p_k) &= 1-p_k&
\Pr(X = 1 \mid S = p_k) &= p_k
\end{align*}
とするとき、以下の問に答えよ。
\vspace{1em}
\begin{enumerate}
\setlength{\itemsep}{1em}
\item $\eta\ge 0,\,\kappa\in[0,1]$について、以下の尤度比検定$E$の誤り確率$\alpha_E$, $\beta_E$をもとめよ。$\eta$の値で場合分けなどしてもとめること。
\begin{align*}
E(x)&=
\begin{cases}
\vspace{.5em}
0&\text{if } \frac{\Pr(X = x\mid S = p_0)}{\Pr(X = x\mid S = p_1)} > \eta\\\vspace{.5em}
1&\text{if } \frac{\Pr(X = x\mid S = p_0)}{\Pr(X = x\mid S = p_1)} < \eta\\
\kappa&\text{otherwise.}
\end{cases}
\end{align*}
\item 任意の検定関数$E\colon A\to[0,1]$で実現可能な$(\alpha_E,\, \beta_E)$の範囲を図示せよ。
\end{enumerate}
\end{frame}

\if0
\begin{frame}{おまけ 1/2}
\footnotesize
\begin{definition}[対称通信路]
$B=\{0,1\}$とする。
通信路$\Pr(X=s\mid S=s)$についてある置換$\sigma\colon A\to A$が存在して
$\sigma^2=\mathrm{id}$で
\begin{align*}
\Pr(X = x\mid S = 0) &= \Pr(X = \sigma(x)\mid S = 1)
\end{align*}
が成り立つとき$\Pr(X=x\mid S=s)$を\emm{対称通信路}という。
\end{definition}
$\lambda=1/2$と$\Pr(X=x\mid S=s)$が対称通信路であることを仮定すると、
\begin{align*}
&\lambda \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le \log\frac{1-\lambda}{\lambda}\mid S=0\right)\\
&\quad + (1-\lambda) \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \le \log\frac{\lambda}{1-\lambda}\mid S=1\right)\\
&=
\frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right)
+ \frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \le 0\mid S=1\right)\\
&=
\frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right)
+ \frac12 \Pr\left(\emm{\sum_{k=1}^N \log\frac{p(\sigma(\sigma(X_k))\mid 0)}{p(\sigma(\sigma(X_k))\mid 1)}} \le 0\mid S=0\right)\\
&=
\Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right).
\end{align*}
\end{frame}

\begin{frame}{おまけ 2/2}
$Y=\log\frac{p(X\mid 1)}{p(X\mid 0)}$とすると、任意の$t\ge 0$について
\begin{align*}
\Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 0)}{p(X_k\mid 1)}} \le 0\mid S=0\right)
&=\Pr\left(\emm{\sum_{k=1}^N \log\frac{p(X_k\mid 1)}{p(X_k\mid 0)}} \ge 0\mid S=0\right)\\
&\le M_Y(t)^N.
\end{align*}
である。ここで
\begin{align*}
M_Y(t) &= \sum_{x\in A} p_0(x) \left(\frac{p_1(x)}{p_0(x)}\right)^t = \mathrm{e}^{-(1-t)D(p_1||p_0)}
\end{align*}
\begin{definition}[R\'enyi ダイバージェンス]
\begin{align*}
D_\alpha(q||p) &= \frac1{\alpha - 1} \log \sum_{x\in A} q^\alpha(x) p^{1-\alpha}(x)
\end{align*}
\end{definition}
\end{frame}
\fi

\end{document}
